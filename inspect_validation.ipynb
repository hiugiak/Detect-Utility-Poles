{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mask R-CNN - Inspect Validation on ResNet101\n",
    "Inspect and visualize validation code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import itertools\n",
    "import math\n",
    "import logging\n",
    "import json\n",
    "import re\n",
    "import random\n",
    "from collections import OrderedDict\n",
    "import numpy as np\n",
    "import skimage.io\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import matplotlib.lines as lines\n",
    "from matplotlib.patches import Polygon\n",
    "from pycocotools.coco import COCO\n",
    "\n",
    "# Root directory of the project\n",
    "ROOT_DIR = os.path.abspath(\"./\")\n",
    "LOGS_DIR = os.path.join(ROOT_DIR, \"logs\")\n",
    "\n",
    "# Import Mask RCNN\n",
    "sys.path.append(\"Mask_RCNN\")  # To find local version of the library\n",
    "from mrcnn import utils\n",
    "from mrcnn import visualize\n",
    "from mrcnn.visualize import display_images\n",
    "import mrcnn.model as modellib\n",
    "from mrcnn.model import log\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utility_poles as up\n",
    "class InferenceConfig(up.UtilityPoleConfig):\n",
    "    # Set batch size to 1 since we'll be running inference on\n",
    "    # one image at a time. Batch size = GPU_COUNT * IMAGES_PER_GPU\n",
    "    GPU_COUNT = 1\n",
    "    IMAGES_PER_GPU = 1\n",
    "config = InferenceConfig()\n",
    "UP_DIR = os.path.join(ROOT_DIR, 'data_dataset')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model, Weights and Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create model\n",
    "model = modellib.MaskRCNN(mode=\"inference\", config=config, model_dir=LOGS_DIR)\n",
    "# Load weights\n",
    "weights_path = os.path.join(ROOT_DIR, 'mask_rcnn_poles_resnet101.h5')\n",
    "model.load_weights(weights_path, by_name=True)\n",
    "\n",
    "# Load dataset\n",
    "if config.NAME == \"poles\":\n",
    "    dataset = up.UtilityPoleDataset()\n",
    "    dataset.load_pole(UP_DIR, \"val\")\n",
    "\n",
    "# Must call before using the dataset\n",
    "dataset.prepare()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## COCO Evaluation\n",
    "Measuring the accuracy of object detectors in AP."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "cocoGt=COCO(\"{}/val/annotations.json\".format(UP_DIR))\n",
    "cocoEval, cocoResults = up.evaluate_coco(model, dataset, cocoGt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "cocoResults = sorted(cocoResults, key=lambda i: i['score'], reverse=True)\n",
    "class_ids = [i['category_id'] for i in cocoResults]\n",
    "image_ids = np.array([i['image_id'] for i in cocoResults])\n",
    "coco_bboxes = [i['bbox'] for i in cocoResults]\n",
    "bboxes = np.array([])\n",
    "rois = np.array([])\n",
    "class_ids = np.array([])\n",
    "scores = np.array([[]])\n",
    "masks = np.array([[]])\n",
    "ious = np.array([])\n",
    "\n",
    "# Detect\n",
    "for i, image_id in enumerate(dataset.image_ids):\n",
    "    gt_masks, gt_class_ids = dataset.load_mask(image_id)\n",
    "    gt_bboxes = utils.extract_bboxes(gt_masks)\n",
    "    \n",
    "    image = dataset.load_image(image_id)\n",
    "    pred = model.detect([image], verbose=1)[0]\n",
    "    rois = np.append(rois, pred['rois'])\n",
    "    class_ids = np.append(class_ids, pred['class_ids'])\n",
    "    scores = np.append(scores, pred['scores'])\n",
    "    \n",
    "    if pred['rois'].shape[0] > 0:\n",
    "        overlaps = utils.compute_overlaps(pred['rois'], gt_bboxes)\n",
    "        overlaps = np.amax(overlaps, axis=1)\n",
    "        ious = np.append(ious, overlaps)\n",
    "        \n",
    "    visualize.display_differences(image, gt_bboxes, gt_class_ids, gt_masks,\n",
    "                                  pred['rois'], pred['class_ids'], pred['scores'], pred['masks'],\n",
    "                                  dataset.class_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Precisions and Recalls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "score_ind = np.argsort(-scores)\n",
    "\n",
    "from prettytable import PrettyTable\n",
    "\n",
    "pred_gt_table = PrettyTable(['IoU', 'Score', ])\n",
    "for i, ind in enumerate(score_ind):\n",
    "    pred_gt_table.add_row(['{:.2f}'.format(ious[ind]), '{:.2f}'.format(scores[ind])])\n",
    "print(pred_gt_table)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Mask R-CNN",
   "language": "python",
   "name": "mask_r_cnn"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
